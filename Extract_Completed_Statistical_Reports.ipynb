{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Extract completed statistical reports to refactored CSVs\n",
        "\n",
        "This notebook reads completed ATI/Privacy/Supplemental XLSX files (EN or FR) and appends rows to refactored-style CSVs.\n",
        "It uses the hidden *ForConsumption mapping sheets to map each Q* id to a workbook cell, and can skip formula\n",
        "cells (auto-calculated totals).\n",
        "\n",
        "During development, output CSVs default to `test_data/`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import re\n",
        "import unicodedata\n",
        "\n",
        "import pandas as pd\n",
        "import openpyxl\n",
        "from openpyxl.cell.cell import ArrayFormula\n",
        "from openpyxl.utils import get_column_letter, column_index_from_string\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Inputs\n",
        "REPORT_YEAR = '2023'\n",
        "INPUT_FILES = sorted(Path('test_data').glob(f'*_{REPORT_YEAR}_*.xlsx'))\n",
        "# Outputs (use test_data during development)\n",
        "OUTPUT_DIR = Path('test_data')\n",
        "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "ATI_OUTPUT_CSV = OUTPUT_DIR / 'ATI-AI_refactored_from_xlsx.csv'\n",
        "PRIVACY_OUTPUT_CSV = OUTPUT_DIR / 'Privacy-AI_refactored_from_xlsx.csv'\n",
        "SUPPLEMENTAL_OUTPUT_CSV = OUTPUT_DIR / 'Supplemental-AI_refactored_from_xlsx.csv'\n",
        "# Reference datasets for metadata and institution lookups\n",
        "ATI_REFERENCE_CSV = Path('ATI-AI_refactored.csv')\n",
        "PRIVACY_REFERENCE_CSV = Path('Privacy-AI_refactored.csv')\n",
        "SUPPLEMENTAL_REFERENCE_CSV = Path('Supplemental-AI_refactored.csv')\n",
        "INCLUDE_FORMULA_CELLS = True  # True to capture calculated totals\n",
        "DROP_EMPTY_ROWS = False        # True to skip empty cells\n",
        "DEDUPLICATE = True             # True to drop duplicates on org/period/id\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "EXPECTED_COLUMNS = [\n",
        "    'gc_orgID',\n",
        "    'institution_en',\n",
        "    'institution_fr',\n",
        "    'ReportingPeriodStart',\n",
        "    'ReportingPeriodEnd',\n",
        "    'id',\n",
        "    'section_number',\n",
        "    'section_name_en',\n",
        "    'section_name_fr',\n",
        "    'subsection_number',\n",
        "    'subsection_name_en',\n",
        "    'subsection_name_fr',\n",
        "    'title_en',\n",
        "    'title_fr',\n",
        "    'value',\n",
        "]\n",
        "\n",
        "REPORT_SPECS = {\n",
        "    'ATI': {\n",
        "        'mapping_sheet': 'ATI_ForConsumption',\n",
        "        'data_sheets': ['ATI', 'LAI'],\n",
        "        'date_cells': ('D8', 'H8'),\n",
        "        'inst_cell_default': 'D6',\n",
        "        'reference_csv': ATI_REFERENCE_CSV,\n",
        "        'output_csv': ATI_OUTPUT_CSV,\n",
        "    },\n",
        "    'Privacy': {\n",
        "        'mapping_sheet': 'Privacy_ForConsumption',\n",
        "        'data_sheets': ['Priv', 'LPRP'],\n",
        "        'date_cells': ('D8', 'H8'),\n",
        "        'inst_cell_default': 'D6',\n",
        "        'reference_csv': PRIVACY_REFERENCE_CSV,\n",
        "        'output_csv': PRIVACY_OUTPUT_CSV,\n",
        "    },\n",
        "    'Supplemental': {\n",
        "        'mapping_sheet': 'ATIP_ForConsumption',\n",
        "        'data_sheets': ['Supplemental Report 2024-25', 'Rapport suppl√©mentaire 2024-25'],\n",
        "        'date_cells': ('D9', 'H9'),\n",
        "        'inst_cell_default': 'D7',\n",
        "        'reference_csv': SUPPLEMENTAL_REFERENCE_CSV,\n",
        "        'output_csv': SUPPLEMENTAL_OUTPUT_CSV,\n",
        "    },\n",
        "}\n",
        "\n",
        "DIRECT_REF_RE = re.compile(r\"=\\s*'?([^'!]+)'?!\\$?([A-Z]+)\\$?(\\d+)\")\n",
        "ARRAY_REF_RE = re.compile(r\"=TRANSPOSE\\('?([^'!]+)'?!\\$?([A-Z]+)\\$?(\\d+):\\$?([A-Z]+)\\$?(\\d+)\\)\")\n",
        "ID_QRC_RE = re.compile(r\"^Q(\\d+)R(\\d+)([A-Za-z]?)C(\\d+)([A-Za-z]?)$\", re.IGNORECASE)\n",
        "\n",
        "\n",
        "def normalize_text(text):\n",
        "    if text is None:\n",
        "        return None\n",
        "    normalized = unicodedata.normalize('NFKD', str(text)).encode('ascii', 'ignore').decode('ascii')\n",
        "    return re.sub(r'\\s+', ' ', normalized).strip().lower() or None\n",
        "\n",
        "\n",
        "def normalize_sub_key(value):\n",
        "    if value is None:\n",
        "        return None\n",
        "    text = str(value).strip()\n",
        "    if text == '' or text.lower() == 'nan':\n",
        "        return None\n",
        "    if text.endswith('.0'):\n",
        "        text = text[:-2]\n",
        "    return text.replace(',', '.')\n",
        "\n",
        "\n",
        "def build_refactored_id(key_text, sub_key, report_type):\n",
        "    if report_type == 'Supplemental':\n",
        "        return key_text\n",
        "    match = ID_QRC_RE.match(str(key_text).strip())\n",
        "    if not match:\n",
        "        return key_text\n",
        "    row_num = match.group(2)\n",
        "    row_suffix = (match.group(3) or '').lower()\n",
        "    cell_num = match.group(4)\n",
        "    cell_suffix = (match.group(5) or '').lower()\n",
        "    if not sub_key:\n",
        "        return key_text\n",
        "    sub_text = str(sub_key).replace(',', '.').strip()\n",
        "    if '.' in sub_text:\n",
        "        section, subsection = sub_text.split('.', 1)\n",
        "        section = section.strip()\n",
        "        subsection = subsection.strip()\n",
        "        if section and subsection:\n",
        "            return f\"Q{section}_{subsection}Row{row_num}{row_suffix}Cell{cell_num}{cell_suffix}\"\n",
        "    if sub_text:\n",
        "        return f\"Q{sub_text}Row{row_num}{row_suffix}Cell{cell_num}{cell_suffix}\"\n",
        "    return key_text\n",
        "\n",
        "\n",
        "def expand_range(start_col, start_row, end_col, end_row):\n",
        "    c1 = column_index_from_string(start_col)\n",
        "    c2 = column_index_from_string(end_col)\n",
        "    r1 = int(start_row)\n",
        "    r2 = int(end_row)\n",
        "    if c2 < c1:\n",
        "        c1, c2 = c2, c1\n",
        "    if r2 < r1:\n",
        "        r1, r2 = r2, r1\n",
        "    cells = []\n",
        "    for row in range(r1, r2 + 1):\n",
        "        for col in range(c1, c2 + 1):\n",
        "            cells.append(f\"{get_column_letter(col)}{row}\")\n",
        "    return cells\n",
        "\n",
        "\n",
        "def parse_direct_ref(formula):\n",
        "    match = DIRECT_REF_RE.match(str(formula).strip())\n",
        "    if not match:\n",
        "        return None, None\n",
        "    sheet = match.group(1).strip(\"'\")\n",
        "    cell = f\"{match.group(2)}{match.group(3)}\"\n",
        "    return sheet, cell\n",
        "\n",
        "\n",
        "def parse_array_formula(text):\n",
        "    match = ARRAY_REF_RE.match(str(text).strip())\n",
        "    if not match:\n",
        "        return None, []\n",
        "    sheet = match.group(1).strip(\"'\")\n",
        "    cells = expand_range(match.group(2), match.group(3), match.group(4), match.group(5))\n",
        "    return sheet, cells\n",
        "\n",
        "\n",
        "def build_row_targets(ws):\n",
        "    row_to_target = {}\n",
        "    seen_refs = set()\n",
        "\n",
        "    for row in range(1, ws.max_row + 1):\n",
        "        value = ws.cell(row=row, column=2).value\n",
        "        if isinstance(value, ArrayFormula):\n",
        "            if value.ref in seen_refs:\n",
        "                continue\n",
        "            seen_refs.add(value.ref)\n",
        "            ref_match = re.match(r'B(\\d+):B(\\d+)', value.ref)\n",
        "            if not ref_match:\n",
        "                continue\n",
        "            start_row = int(ref_match.group(1))\n",
        "            end_row = int(ref_match.group(2))\n",
        "            sheet, cells = parse_array_formula(value.text)\n",
        "            if not sheet or not cells:\n",
        "                continue\n",
        "            for idx, target_row in enumerate(range(start_row, end_row + 1)):\n",
        "                if idx < len(cells):\n",
        "                    row_to_target[target_row] = (sheet, cells[idx])\n",
        "\n",
        "    for row in range(1, ws.max_row + 1):\n",
        "        if row in row_to_target:\n",
        "            continue\n",
        "        value = ws.cell(row=row, column=2).value\n",
        "        if isinstance(value, str) and value.startswith('='):\n",
        "            sheet, cell = parse_direct_ref(value)\n",
        "            if sheet and cell:\n",
        "                row_to_target[row] = (sheet, cell)\n",
        "\n",
        "    return row_to_target\n",
        "\n",
        "\n",
        "def find_inst_target(ws, row_to_target):\n",
        "    for row in range(1, ws.max_row + 1):\n",
        "        key = ws.cell(row=row, column=1).value\n",
        "        if key is None:\n",
        "            continue\n",
        "        if str(key).strip().lower() == 'inst':\n",
        "            return row_to_target.get(row)\n",
        "    return None\n",
        "\n",
        "\n",
        "def is_formula_cell(cell):\n",
        "    if cell.data_type == 'f':\n",
        "        return True\n",
        "    value = cell.value\n",
        "    return isinstance(value, str) and value.startswith('=')\n",
        "\n",
        "\n",
        "def get_merged_cell_value(ws, cell_ref):\n",
        "    for merged_range in ws.merged_cells.ranges:\n",
        "        if cell_ref in merged_range:\n",
        "            start_cell = merged_range.start_cell\n",
        "            if hasattr(start_cell, \"coordinate\"):\n",
        "                start_ref = start_cell.coordinate\n",
        "            elif hasattr(start_cell, \"coord\"):\n",
        "                start_ref = start_cell.coord\n",
        "            else:\n",
        "                start_ref = str(start_cell)\n",
        "            return ws[start_ref].value\n",
        "    return ws[cell_ref].value\n",
        "\n",
        "\n",
        "def coerce_date(value):\n",
        "    if value is None or str(value).strip() == '':\n",
        "        return None\n",
        "    try:\n",
        "        return pd.to_datetime(value, errors='coerce').date()\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "\n",
        "def normalize_org_id(value):\n",
        "    if value is None:\n",
        "        return None\n",
        "    text = str(value).strip()\n",
        "    if text == '' or text.lower() == 'nan':\n",
        "        return None\n",
        "    try:\n",
        "        return int(float(text))\n",
        "    except Exception:\n",
        "        return text\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_reference_maps(csv_path):\n",
        "    if not csv_path or not Path(csv_path).exists():\n",
        "        return None, {}\n",
        "    df = pd.read_csv(csv_path, dtype=str, low_memory=False)\n",
        "\n",
        "    id_meta = {}\n",
        "    for _, row in df.dropna(subset=['id']).iterrows():\n",
        "        id_value = str(row.get('id')).strip()\n",
        "        if id_value and id_value not in id_meta:\n",
        "            id_meta[id_value] = row\n",
        "\n",
        "    inst_lookup = {}\n",
        "    for _, row in df.dropna(subset=['gc_orgID']).iterrows():\n",
        "        gc_org_id = normalize_org_id(row.get('gc_orgID'))\n",
        "        inst_en = row.get('institution_en')\n",
        "        inst_fr = row.get('institution_fr')\n",
        "        for name in [inst_en, inst_fr]:\n",
        "            norm = normalize_text(name)\n",
        "            if norm and norm not in inst_lookup:\n",
        "                inst_lookup[norm] = (gc_org_id, inst_en, inst_fr)\n",
        "\n",
        "    return id_meta, inst_lookup\n",
        "\n",
        "\n",
        "def resolve_institution(inst_name, inst_lookup):\n",
        "    norm = normalize_text(inst_name)\n",
        "    if norm and norm in inst_lookup:\n",
        "        return inst_lookup[norm]\n",
        "    if inst_name is None:\n",
        "        return None, None, None\n",
        "    return None, str(inst_name).strip(), str(inst_name).strip()\n",
        "\n",
        "\n",
        "def read_cell_value(wb, wb_values, sheet_name, cell_ref, include_formula=False):\n",
        "    ws = wb[sheet_name]\n",
        "    cell = ws[cell_ref]\n",
        "    if is_formula_cell(cell):\n",
        "        if not include_formula:\n",
        "            return None, True\n",
        "        if wb_values is not None:\n",
        "            return get_merged_cell_value(wb_values[sheet_name], cell_ref), False\n",
        "    return get_merged_cell_value(ws, cell_ref), False\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "def extract_report_rows(wb, wb_values, report_type, spec, id_meta, inst_lookup):\n",
        "    if spec['mapping_sheet'] not in wb.sheetnames:\n",
        "        return [], {'skipped': f\"missing mapping sheet {spec['mapping_sheet']}\"}\n",
        "    data_sheet = None\n",
        "    for candidate in spec['data_sheets']:\n",
        "        if candidate in wb.sheetnames:\n",
        "            data_sheet = candidate\n",
        "            break\n",
        "    if not data_sheet:\n",
        "        return [], {'skipped': f\"missing data sheet for {report_type}\"}\n",
        "    mapping_ws = wb[spec['mapping_sheet']]\n",
        "    row_to_target = build_row_targets(mapping_ws)\n",
        "    inst_target = find_inst_target(mapping_ws, row_to_target)\n",
        "    inst_sheet, inst_cell = (inst_target if inst_target else (data_sheet, spec['inst_cell_default']))\n",
        "    inst_value = get_merged_cell_value(wb[inst_sheet], inst_cell)\n",
        "    gc_org_id, inst_en, inst_fr = resolve_institution(inst_value, inst_lookup)\n",
        "    start_cell, end_cell = spec['date_cells']\n",
        "    start_value = get_merged_cell_value(wb[data_sheet], start_cell)\n",
        "    end_value = get_merged_cell_value(wb[data_sheet], end_cell)\n",
        "    report_start = coerce_date(start_value)\n",
        "    report_end = coerce_date(end_value)\n",
        "    rows = []\n",
        "    skipped_formula = 0\n",
        "    missing_target = 0\n",
        "    missing_meta = 0\n",
        "    any_value = False\n",
        "    for row in range(1, mapping_ws.max_row + 1):\n",
        "        key = mapping_ws.cell(row=row, column=1).value\n",
        "        if key is None:\n",
        "            continue\n",
        "        key_text = str(key).strip()\n",
        "        if key_text == '' or key_text.lower() == 'inst':\n",
        "            continue\n",
        "        target = row_to_target.get(row)\n",
        "        if not target:\n",
        "            missing_target += 1\n",
        "            continue\n",
        "        sheet_name, cell_ref = target\n",
        "        if sheet_name not in wb.sheetnames:\n",
        "            missing_target += 1\n",
        "            continue\n",
        "        value, is_formula = read_cell_value(wb, wb_values, sheet_name, cell_ref, INCLUDE_FORMULA_CELLS)\n",
        "        if is_formula and not INCLUDE_FORMULA_CELLS:\n",
        "            skipped_formula += 1\n",
        "            continue\n",
        "        value_is_empty = value is None or str(value).strip() == ''\n",
        "        if not value_is_empty:\n",
        "            any_value = True\n",
        "        if DROP_EMPTY_ROWS and value_is_empty:\n",
        "            continue\n",
        "        sub_value = mapping_ws.cell(row=row, column=3).value\n",
        "        sub_key = normalize_sub_key(sub_value)\n",
        "        mapped_id = build_refactored_id(key_text, sub_key, report_type)\n",
        "        meta = id_meta.get(mapped_id) if id_meta else None\n",
        "        if meta is None:\n",
        "            missing_meta += 1\n",
        "        row_data = {\n",
        "            'gc_orgID': gc_org_id,\n",
        "            'institution_en': inst_en,\n",
        "            'institution_fr': inst_fr,\n",
        "            'ReportingPeriodStart': report_start.isoformat() if report_start else None,\n",
        "            'ReportingPeriodEnd': report_end.isoformat() if report_end else None,\n",
        "            'id': mapped_id,\n",
        "            'section_number': meta.get('section_number') if meta is not None else None,\n",
        "            'section_name_en': meta.get('section_name_en') if meta is not None else None,\n",
        "            'section_name_fr': meta.get('section_name_fr') if meta is not None else None,\n",
        "            'subsection_number': meta.get('subsection_number') if meta is not None else sub_key,\n",
        "            'subsection_name_en': meta.get('subsection_name_en') if meta is not None else None,\n",
        "            'subsection_name_fr': meta.get('subsection_name_fr') if meta is not None else None,\n",
        "            'title_en': meta.get('title_en') if meta is not None else None,\n",
        "            'title_fr': meta.get('title_fr') if meta is not None else None,\n",
        "            'value': value,\n",
        "        }\n",
        "        rows.append(row_data)\n",
        "    if not any_value:\n",
        "        return [], {'skipped': f\"no values found for {report_type}\", 'data_sheet': data_sheet}\n",
        "    stats = {\n",
        "        'rows': len(rows),\n",
        "        'skipped_formula': skipped_formula,\n",
        "        'missing_target': missing_target,\n",
        "        'missing_meta': missing_meta,\n",
        "        'data_sheet': data_sheet,\n",
        "    }\n",
        "    return rows, stats\n",
        "def append_rows_to_csv(output_path, rows):\n",
        "    if not rows:\n",
        "        return 0\n",
        "    new_df = pd.DataFrame(rows)\n",
        "    for col in EXPECTED_COLUMNS:\n",
        "        if col not in new_df.columns:\n",
        "            new_df[col] = pd.NA\n",
        "    new_df = new_df[EXPECTED_COLUMNS]\n",
        "    if output_path.exists():\n",
        "        existing = pd.read_csv(output_path, dtype=str, low_memory=False)\n",
        "        for col in EXPECTED_COLUMNS:\n",
        "            if col not in existing.columns:\n",
        "                existing[col] = pd.NA\n",
        "        existing = existing[EXPECTED_COLUMNS]\n",
        "        combined = pd.concat([existing, new_df], ignore_index=True)\n",
        "        if DEDUPLICATE:\n",
        "            combined = combined.drop_duplicates(\n",
        "                subset=['gc_orgID', 'ReportingPeriodStart', 'ReportingPeriodEnd', 'id'],\n",
        "                keep='last',\n",
        "            )\n",
        "    else:\n",
        "        combined = new_df\n",
        "    combined.to_csv(output_path, index=False)\n",
        "    return len(new_df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load reference maps once per report type\n",
        "REFERENCE_MAPS = {}\n",
        "for report_type, spec in REPORT_SPECS.items():\n",
        "    id_meta, inst_lookup = load_reference_maps(spec['reference_csv'])\n",
        "    REFERENCE_MAPS[report_type] = (id_meta or {}, inst_lookup or {})\n",
        "\n",
        "summary = []\n",
        "\n",
        "for path in INPUT_FILES:\n",
        "    wb = openpyxl.load_workbook(path, data_only=False)\n",
        "    wb_values = openpyxl.load_workbook(path, data_only=True) if INCLUDE_FORMULA_CELLS else None\n",
        "\n",
        "    for report_type, spec in REPORT_SPECS.items():\n",
        "        id_meta, inst_lookup = REFERENCE_MAPS[report_type]\n",
        "        rows, stats = extract_report_rows(wb, wb_values, report_type, spec, id_meta, inst_lookup)\n",
        "        if not rows:\n",
        "            continue\n",
        "        appended = append_rows_to_csv(spec['output_csv'], rows)\n",
        "        summary.append((path.name, report_type, appended, stats))\n",
        "\n",
        "summary\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
